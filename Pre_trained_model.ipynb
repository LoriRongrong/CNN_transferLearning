{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir= ''\n",
    "model_name = \"resnet\"# \"alexnet\", \"densenet\", 'vgg', 'resnet'\n",
    "num_classes = 10\n",
    "batch_size = 1\n",
    "num_epochs = 15\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTZANDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx][0]\n",
    "        y = self.data[idx][1]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        \n",
    "        x = torch.Tensor(x)\n",
    "\n",
    "        return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "GTZAN_data = pickle.load(open('data/GTZAN_resized.train', 'rb'))\n",
    "trainset = GTZANDataset(GTZAN_data)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "GTZAN_data = pickle.load(open('data/GTZAN_resized.test', 'rb'))\n",
    "testset = GTZANDataset(GTZAN_data)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders_dict = {'train': trainloader, 'test':testloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [resnet, alexnet, vgg, squeezenet, densenet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders,criterion, opt,epochs):\n",
    "    since = time.time()\n",
    "    avg_loss = []\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    avg_acc = []\n",
    "    print_freq = 100\n",
    "    model = model.cuda()\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            opt.zero_grad()\n",
    "             # forward\n",
    "            # track history if only in train\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs,1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        # statistics\n",
    "            running_loss += loss.item() \n",
    "            running_acc += torch.sum(preds == labels.data)\n",
    "#             scheduler.step()\n",
    "            if i % print_freq == print_freq - 1: # Print every several mini-batches.\n",
    "                losses = running_loss / print_freq\n",
    "                acc = running_acc / (print_freq*batch_size)\n",
    "                print('[epoch: {}, i: {:5d}] avg mini-batch loss: {:.3f}, acc: {:.3f}'.format(\n",
    "                    epoch, i, losses, acc))\n",
    "                avg_loss.append(losses)\n",
    "                avg_acc.append(acc)\n",
    "                running_loss = 0.0\n",
    "                running_acc = 0.0\n",
    "            # deep copy the model\n",
    "            \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "#     print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    \"\"\"this is only useful if we want to combine training and eval states\"\"\"\n",
    "    # load best model weights\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "    return model, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /tmp/xdg-cache/torch/checkpoints/resnet18-5c106cde.pth\n",
      "100%|██████████| 44.7M/44.7M [00:02<00:00, 20.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg16_bn(pretrained=use_pretrained)\n",
    "        \n",
    "        \"\"\"this is uncomment if we want to freeze the inner layer\"\"\"\n",
    "        # freeze inner layer\n",
    "#         for param in model_ft.parameters():\n",
    "#             param.requires_grad = False  # will this cause a problem for the first layer?\n",
    "        \n",
    "        model_ft.features[0] = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        \n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224 # what does it mean?\n",
    "    \n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "#         set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.features[0] = nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
    "        model_ft.features[12] = nn.MaxPool2d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224 \n",
    "    \n",
    "    elif model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "#         set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t layer1.0.conv1.weight\n",
      "\t layer1.0.bn1.weight\n",
      "\t layer1.0.bn1.bias\n",
      "\t layer1.0.conv2.weight\n",
      "\t layer1.0.bn2.weight\n",
      "\t layer1.0.bn2.bias\n",
      "\t layer1.1.conv1.weight\n",
      "\t layer1.1.bn1.weight\n",
      "\t layer1.1.bn1.bias\n",
      "\t layer1.1.conv2.weight\n",
      "\t layer1.1.bn2.weight\n",
      "\t layer1.1.bn2.bias\n",
      "\t layer2.0.conv1.weight\n",
      "\t layer2.0.bn1.weight\n",
      "\t layer2.0.bn1.bias\n",
      "\t layer2.0.conv2.weight\n",
      "\t layer2.0.bn2.weight\n",
      "\t layer2.0.bn2.bias\n",
      "\t layer2.0.downsample.0.weight\n",
      "\t layer2.0.downsample.1.weight\n",
      "\t layer2.0.downsample.1.bias\n",
      "\t layer2.1.conv1.weight\n",
      "\t layer2.1.bn1.weight\n",
      "\t layer2.1.bn1.bias\n",
      "\t layer2.1.conv2.weight\n",
      "\t layer2.1.bn2.weight\n",
      "\t layer2.1.bn2.bias\n",
      "\t layer3.0.conv1.weight\n",
      "\t layer3.0.bn1.weight\n",
      "\t layer3.0.bn1.bias\n",
      "\t layer3.0.conv2.weight\n",
      "\t layer3.0.bn2.weight\n",
      "\t layer3.0.bn2.bias\n",
      "\t layer3.0.downsample.0.weight\n",
      "\t layer3.0.downsample.1.weight\n",
      "\t layer3.0.downsample.1.bias\n",
      "\t layer3.1.conv1.weight\n",
      "\t layer3.1.bn1.weight\n",
      "\t layer3.1.bn1.bias\n",
      "\t layer3.1.conv2.weight\n",
      "\t layer3.1.bn2.weight\n",
      "\t layer3.1.bn2.bias\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n",
      "Epoch 0/14\n",
      "----------\n",
      "[epoch: 0, i:    99] avg mini-batch loss: 2.357, acc: 0.242\n",
      "Epoch 1/14\n",
      "----------\n",
      "[epoch: 1, i:    99] avg mini-batch loss: 1.935, acc: 0.352\n",
      "Epoch 2/14\n",
      "----------\n",
      "[epoch: 2, i:    99] avg mini-batch loss: 1.816, acc: 0.386\n",
      "Epoch 3/14\n",
      "----------\n",
      "[epoch: 3, i:    99] avg mini-batch loss: 1.638, acc: 0.456\n",
      "Epoch 4/14\n",
      "----------\n",
      "[epoch: 4, i:    99] avg mini-batch loss: 1.579, acc: 0.488\n",
      "Epoch 5/14\n",
      "----------\n",
      "[epoch: 5, i:    99] avg mini-batch loss: 1.349, acc: 0.514\n",
      "Epoch 6/14\n",
      "----------\n",
      "[epoch: 6, i:    99] avg mini-batch loss: 1.285, acc: 0.566\n",
      "Epoch 7/14\n",
      "----------\n",
      "[epoch: 7, i:    99] avg mini-batch loss: 1.150, acc: 0.608\n",
      "Epoch 8/14\n",
      "----------\n",
      "[epoch: 8, i:    99] avg mini-batch loss: 1.141, acc: 0.628\n",
      "Epoch 9/14\n",
      "----------\n",
      "[epoch: 9, i:    99] avg mini-batch loss: 1.048, acc: 0.618\n",
      "Epoch 10/14\n",
      "----------\n",
      "[epoch: 10, i:    99] avg mini-batch loss: 0.967, acc: 0.676\n",
      "Epoch 11/14\n",
      "----------\n",
      "[epoch: 11, i:    99] avg mini-batch loss: 0.833, acc: 0.708\n",
      "Epoch 12/14\n",
      "----------\n",
      "[epoch: 12, i:    99] avg mini-batch loss: 0.576, acc: 0.804\n",
      "Epoch 13/14\n",
      "----------\n",
      "[epoch: 13, i:    99] avg mini-batch loss: 0.597, acc: 0.810\n",
      "Epoch 14/14\n",
      "----------\n",
      "[epoch: 14, i:    99] avg mini-batch loss: 0.670, acc: 0.772\n",
      "Training complete in 0m 56s\n"
     ]
    }
   ],
   "source": [
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001,momentum=0.9)\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft,avg_loss = train_model(model_ft, trainloader, \n",
    "                             criterion, optimizer_ft, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(), 'resnet_on_GTZAN_resized_batchsize_5_epoch_15.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_loss, 'b', label='default')\n",
    "print_freq = 100\n",
    "plt.xlabel('mini-batch index / {}'.format(print_freq))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_trained: Accuracy of the network on the 10000 test images: 42 %\n"
     ]
    }
   ],
   "source": [
    "# Get test accuracy.\n",
    "correct_net = 0\n",
    "correct_cnn = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs_cnn = model_ft(images)\n",
    "\n",
    "        _, predicted_cnn = torch.max(outputs_cnn.data, 1)\n",
    "        total += labels.size(0)\n",
    "\n",
    "        correct_cnn += (predicted_cnn == labels).sum().item()\n",
    "\n",
    "\n",
    "print('pre_trained: Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct_cnn / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of blues : 42 %\n",
      "Accuracy of classical : 63 %\n",
      "Accuracy of country : 39 %\n",
      "Accuracy of disco : 29 %\n",
      "Accuracy of hiphop : 53 %\n",
      "Accuracy of  jazz : 66 %\n",
      "Accuracy of metal : 84 %\n",
      "Accuracy of   pop : 25 %\n",
      "Accuracy of reggae : 26 %\n",
      "Accuracy of  rock : 48 %\n"
     ]
    }
   ],
   "source": [
    "classes = ('blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock')\n",
    "truths = []\n",
    "preds = []\n",
    "# Get test accuracy for each class.\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model_ft(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        if type(c) is not list:\n",
    "            c = [c]\n",
    "#         print (\"outside: \", c)\n",
    "#         print (\"separate: \", c[0][0])\n",
    "#         print (\"separate: \", c[1])\n",
    "#         print (\"separate: \", c[2])\n",
    "        for i in range(batch_size):\n",
    "            preds.append(predicted[i].item())\n",
    "            \n",
    "            truths.append(labels[i].item())\n",
    "\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[0][i]\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
