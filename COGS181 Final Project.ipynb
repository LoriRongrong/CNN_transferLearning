{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from skorch import NeuralNetRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_X_y(data):\n",
    "    data_X = data[:, :-1]\n",
    "    data_y = data[:, -1]\n",
    "    return data_X, data_y\n",
    "\n",
    "def split_train_test(data, train_ratio):\n",
    "    X, y = split_X_y(data)\n",
    "    \n",
    "    num_training = len(X) * train_ratio\n",
    "    try:\n",
    "        assert(num_training % 1 == 0)\n",
    "    except:\n",
    "        print('len(X) = ' + str(len(X)))\n",
    "        print('train ratio = ' + str(train_ratio))\n",
    "        print(str(num_training) + ' training samples')\n",
    "        print(len(X))\n",
    "        for i in range(1, len(X)):\n",
    "            if len(X) % i == 0:\n",
    "                print(i)\n",
    "    num_training = int(num_training)\n",
    "                \n",
    "    perm = np.random.permutation(len(X))\n",
    "    X_shuffled = X[perm]\n",
    "    y_shuffled = y[perm]\n",
    "\n",
    "    X_train = X_shuffled[:num_training]\n",
    "    y_train = y_shuffled[:num_training]\n",
    "    X_test = X_shuffled[num_training:]\n",
    "    y_test = y_shuffled[num_training:]\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "    \n",
    "def draw_heatmap_2d(training_errors, gamma_list, C_list, title, xlabel, ylabel, large=True):\n",
    "    if large:\n",
    "        plt.figure(figsize = (10,6))\n",
    "    ax = sns.heatmap(training_errors, annot=True, fmt='.3f', \n",
    "                     xticklabels=gamma_list, yticklabels=C_list)\n",
    "    ax.collections[0].colorbar.set_label(\"error\")\n",
    "    ax.set(xlabel=xlabel, ylabel=ylabel)\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(20*8*8, 100)\n",
    "        self.fc2 = nn.Linear(100, 10) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 20*8*8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(X_train, Y_train, X_test, Y_test, draw=False):\n",
    "    net = NeuralNetRegressor(Net, max_epochs=100, lr=0.001, verbose=1)\n",
    "    \n",
    "    params = {\n",
    "        'lr': [0.001,0.005, 0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "        'max_epochs': list(range(500,5500, 500))\n",
    "    }\n",
    "\n",
    "    gs = GridSearchCV(net, params, refit=False, scoring='r2', verbose=1, cv=10)\n",
    "    \n",
    "    grid_search.fit(X_train, Y_train)\n",
    "    \n",
    "    cross_val_errors = 1 - grid_search.cv_results_['mean_test_score'].reshape(4,9)\n",
    "    if draw:\n",
    "        draw_heatmap_2d(cross_val_errors, k_list, metric_list, title='cross-validation error w.r.t k and distance metric', ylabel='metric', xlabel='k', large=True)\n",
    "    \n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"Best params: {}\".format(best_params))\n",
    "\n",
    "    best_test_accuracy = (Y_test == grid_search.best_estimator_.predict(X_test)).sum() / len(Y_test)\n",
    "    best_train_accuracy = (Y_train == grid_search.best_estimator_.predict(X_train)).sum() / len(Y_train)\n",
    "\n",
    "    return best_train_accuracy, best_test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'processed_data/'\n",
    "\n",
    "# Choose: encoded, normalized, pca (Note: the encoded and normalized dataset files were too big for gradescope)\n",
    "option = 'normalized'\n",
    "\n",
    "adult_data = pickle.load(open(data_dir + 'adult_data_%s.p' % option, 'rb'))\n",
    "adult_data = adult_data\n",
    "\n",
    "grade_data = pickle.load(open(data_dir + 'grade_data_%s.p' % option, 'rb'))\n",
    "grade_data = grade_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_names = ['Adult', 'Grades']\n",
    "datasets = [adult_data, grade_data]\n",
    "models = [cnn]\n",
    "model_names = ['CNN']\n",
    "partition = 0.8\n",
    "num_trials = 3\n",
    "best_loss = sys.maxsize\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    random.shuffle(dataset)\n",
    "    if len(dataset) > len(adult_data):\n",
    "        dataset = dataset[:len(adult_data)]\n",
    "        datasets[i] = dataset\n",
    "    \n",
    "    print('DATASET: ' + dataset_names[i])\n",
    "    print(dataset.shape)      \n",
    "    print('% TRAINING: ' + str(partition))\n",
    "    data_train, data_test = split_train_test(dataset, partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dataset in enumerate(datasets):      \n",
    "    print('DATASET: ' + dataset_names[i])\n",
    "    print('% TRAINING: ' + str(partition))\n",
    "    print('-------------------------------------')\n",
    "\n",
    "    model_acc_sums = np.zeros((len(models), 2))\n",
    "    for k in range(num_trials):\n",
    "        print('TRIAL: %d' % (k+1))\n",
    "        print('---------')\n",
    "        data_train, data_test = split_train_test(dataset, partition)\n",
    "\n",
    "        for j, model in enumerate(models):\n",
    "            print('MODEL: %s' % model_names[j])\n",
    "\n",
    "            train_acc, test_acc = model(data_train[0][:], data_train[1][:], data_test[0][:], data_test[1][:], draw=True)\n",
    "\n",
    "            print('TRIAL TRAIN ACCURACY FOR DATASET FOR MODEL: ' + str(train_acc))\n",
    "            print('TRIAL TEST ACCURACY FOR DATASET FOR MODEL: ' + str(test_acc))\n",
    "            print()\n",
    "\n",
    "            model_acc_sums[j][0] += train_acc\n",
    "            model_acc_sums[j][1] += test_acc\n",
    "\n",
    "    print('-----RESULTS-----')\n",
    "    print('DATASET: ' + dataset_names[i])\n",
    "    print('% TRAINING: ' + str(partition))\n",
    "    print()\n",
    "    for j, model in enumerate(model_names):\n",
    "        print('MODEL: %s' % model_names[j])\n",
    "        avg_train_acc = round(model_acc_sums[j][0] / num_trials, 2)\n",
    "        avg_test_acc = round(model_acc_sums[j][1] / num_trials, 2)\n",
    "\n",
    "        print('AVG TRAIN ACCURACY FOR %s WITH %s DATASET WITH %s TRAINING SPLIT: %s' % (model_names[j], dataset_names[i], partition, str(avg_train_acc)))\n",
    "        print('AVG TEST ACCURACY FOR %s WITH %s DATASET WITH %s TRAINING SPLIT: %s' % (model_names[j], dataset_names[i], partition, str(avg_test_acc)))\n",
    "        print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
