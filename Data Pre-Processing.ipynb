{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from os import path\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_all(images_2d, wanted_shape):\n",
    "    res_images = []\n",
    "    for image in images_2d:\n",
    "        resized = cv2.resize(image[0], dsize=wanted_shape)\n",
    "        #print(resized.shape)\n",
    "        res_images.append([resized])\n",
    "    return res_images\n",
    "\n",
    "def normalize_and_pca(images_2d, variance, normalize_only=False, pca_only=False):\n",
    "    orig_x = images_2d[0][0].shape[0]\n",
    "    orig_y = images_2d[0][0].shape[1]\n",
    "    image_length = orig_x * orig_y\n",
    "    images_1d = []\n",
    "    \n",
    "    for image in images_2d:\n",
    "        images_1d.append(image[0].reshape((image_length)))\n",
    "    \n",
    "    data_encoded = images_1d\n",
    "    \n",
    "    # normalize\n",
    "    if not pca_only:\n",
    "        data_encoded = preprocessing.normalize(data_encoded)\n",
    "\n",
    "        if normalize_only:\n",
    "            images_2d = []\n",
    "            for i in range(len(data_encoded)):\n",
    "                images_2d.append([data_encoded[i].reshape(orig_x, orig_y)])\n",
    "            return images_2d\n",
    "    \n",
    "    # pca\n",
    "    pca = PCA(n_components=variance) # Used instead of k to compute minimum number of dimensions to preserve % of variance\n",
    "    X_reduced = pca.fit(data_encoded).transform(data_encoded)\n",
    "    X_recovered = pca.inverse_transform(X_reduced)\n",
    "    \n",
    "    images_2d = []\n",
    "    for i in range(len(X_recovered)):\n",
    "        images_2d.append([X_recovered[i].reshape(orig_x, orig_y)])\n",
    "    return images_2d\n",
    "    \n",
    "def mel_spect(filepath):\n",
    "    y, sr = librosa.load(filepath)\n",
    "    mel_spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\n",
    "    mel_spect = librosa.power_to_db(mel_spect, ref=np.max)\n",
    "    #librosa.display.specshow(mel_spect, y_axis='mel', fmax=8000, x_axis='time');\n",
    "    return mel_spect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GTZAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "labels = []\n",
    "dir_name = 'genres/'\n",
    "for path in Path(dir_name).rglob('*.wav'):\n",
    "    x = mel_spect(path)\n",
    "\n",
    "    y_padding = 660 - x.shape[1]\n",
    "    d = np.zeros((128, y_padding))\n",
    "    x = np.hstack((x, d))\n",
    "\n",
    "    print(x.shape)\n",
    "    assert(x.shape == (128, 660))\n",
    "\n",
    "    X.append(np.array([x]))\n",
    "    labels.append(path.name.split('.')[0])\n",
    "\n",
    "# Y to int label\n",
    "Y = []\n",
    "unique_labels = list(np.unique(labels))\n",
    "for i, y in enumerate(labels):\n",
    "    Y.append(unique_labels.index(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "labels = []\n",
    "dir_name = 'raw_data/fma/fma_medium'\n",
    "\n",
    "try:\n",
    "    for path in Path(dir_name).rglob('*.wav'):\n",
    "        print(path)\n",
    "        try:\n",
    "            x = mel_spect(path)\n",
    "\n",
    "            y_padding = 660 - x.shape[1]\n",
    "            d = np.zeros((128, y_padding))\n",
    "            x = np.hstack((x, d))\n",
    "\n",
    "            #print(x.shape)\n",
    "            assert(x.shape == (128, 660))\n",
    "\n",
    "            X.append(np.array([x]))\n",
    "            labels.append(path.name.split('.')[0])\n",
    "        except Exception as e:\n",
    "            print('failed')\n",
    "            print(e)\n",
    "            print(path)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    # Y to int label\n",
    "    Y = []\n",
    "    unique_labels = list(np.unique(labels))\n",
    "    for i, y in enumerate(labels):\n",
    "        Y.append(unique_labels.index(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAVDESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None\n",
    "with open('raw_data/design_matrix.tab') as players_data:\n",
    "    data = players_data.read()\n",
    "    \n",
    "data = data.split('\\t')\n",
    "\n",
    "label_nums = []\n",
    "\n",
    "for i, d in enumerate(data):\n",
    "    if i > 7 and i % 7 == 0:\n",
    "        label_nums.append(int(d.split('\\n')[0]))\n",
    "        \n",
    "X = []\n",
    "labels = []\n",
    "dir_name = 'raw_data/ravdess/'\n",
    "for i, path in enumerate(Path(dir_name).rglob('*.wav')):\n",
    "    x = mel_spect(path)\n",
    "\n",
    "    if x.shape[1] > 660:\n",
    "        print(x.shape)\n",
    "        continue\n",
    "    \n",
    "    y_padding = 660 - x.shape[1]\n",
    "    d = np.zeros((128, y_padding))\n",
    "    x = np.hstack((x, d))\n",
    "\n",
    "    assert(x.shape == (128, 660))\n",
    "\n",
    "    X.append(np.array([x]))\n",
    "    labels.append(label_nums[i])\n",
    "    \n",
    "Y = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "labels = []\n",
    "dir_name = 'raw_data/stimuli/test-stimuli-200-2009-05-29/'\n",
    "for i, path in enumerate(Path(dir_name).rglob('*.wav')):\n",
    "    x = mel_spect(path)\n",
    "\n",
    "    if x.shape[1] > 660:\n",
    "        print(x.shape)\n",
    "        continue\n",
    "    \n",
    "    y_padding = 660 - x.shape[1]\n",
    "    d = np.zeros((128, y_padding))\n",
    "    x = np.hstack((x, d))\n",
    "\n",
    "    assert(x.shape == (128, 660))\n",
    "\n",
    "    X.append(np.array([x]))\n",
    "    labels.append(label_nums[i])\n",
    "    \n",
    "Y = [l - 1 for l in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resized = resize_all(X, (165, 32))\n",
    "X_pca = normalize_and_pca(np.array(X_resized), variance=0.3, normalize_only=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "\n",
    "train = []\n",
    "for i in range(len(X_train)):\n",
    "    sample = (X_train[i], y_train[i])\n",
    "    train.append(sample)\n",
    "    \n",
    "test = []\n",
    "for i in range(len(X_test)):\n",
    "    sample = (X_test[i], y_test[i])\n",
    "    test.append(sample)\n",
    "    \n",
    "pickle.dump(train, open('data/GTZAN_resized.train', 'wb'))\n",
    "pickle.dump(test, open('data/GTZAN_resized.test', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train[50][0][0], interpolation='nearest')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
